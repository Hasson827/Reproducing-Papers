{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGè®ºæ–‡å¤ç°\n",
    "\n",
    "## â­ VGGçš„ä¸»è¦ç‰¹ç‚¹\n",
    "1. **ç»“æ„ç®€å•ï¼š**\n",
    "\n",
    "å…¨éƒ¨ä½¿ç”¨3Ã—3å·ç§¯æ ¸ï¼Œæ­¥å¹…ä¸º1ï¼Œå¡«å……ä¸º1ï¼Œä¿æŒç‰¹å¾å›¾å¤§å°ä¸å˜ã€‚\n",
    "\n",
    "2Ã—2æœ€å¤§æ± åŒ–å±‚ï¼Œæ­¥å¹…ä¸º2ï¼Œç”¨äºä¸‹é‡‡æ ·ã€‚\n",
    "\n",
    "2. **æ·±å±‚ç½‘ç»œï¼š**\n",
    "\n",
    "é€šè¿‡å †å å¤šä¸ªå·ç§¯å±‚æ¥å¢åŠ æ·±åº¦ï¼Œä»è€Œæå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼ŒVGG16 çš„æ¶æ„ä¸ºï¼š\n",
    "```css\n",
    "[Conv3-64] Ã—2 â†’ MaxPool â†’ [Conv3-128] Ã—2 â†’ MaxPool â†’ \n",
    "[Conv3-256] Ã—3 â†’ MaxPool â†’ [Conv3-512] Ã—3 â†’ MaxPool â†’ \n",
    "[Conv3-512] Ã—3 â†’ MaxPool â†’ FC-4096 â†’ FC-4096 â†’ FC-1000 â†’ Softmax\n",
    "```\n",
    "3. **å…¨è¿æ¥å±‚ï¼š**\n",
    "\n",
    "åœ¨å·ç§¯å±‚ä¹‹åï¼ŒVGGä½¿ç”¨å…¨è¿æ¥å±‚ï¼ˆFCå±‚ï¼‰è¿›è¡Œåˆ†ç±»ã€‚\n",
    "\n",
    "VGG16å’ŒVGG19éƒ½ä½¿ç”¨ä¸¤ä¸ª4096ç»´çš„å…¨è¿æ¥å±‚å’Œä¸€ä¸ª1000ç»´çš„è¾“å‡ºå±‚ï¼ˆå¯¹åº”ImageNet 1000ç±»ï¼‰ã€‚\n",
    "\n",
    "4. **æƒé‡å¯è¿ç§»ï¼š**\n",
    "\n",
    "VGGæ¨¡å‹åœ¨ImageNetä¸Šçš„é¢„è®­ç»ƒæƒé‡å¸¸ç”¨äºè¿ç§»å­¦ä¹ ï¼Œåœ¨è®¸å¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ˆå¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ï¼‰ä¸­è¡¨ç°ä¼˜å¼‚ã€‚\n",
    "\n",
    "## âš¡ VGGçš„ä¼˜åŠ¿ä¸åŠ£åŠ¿\n",
    "1. **âœ… ä¼˜ç‚¹ï¼š**\n",
    "\n",
    "æ¶æ„ç»Ÿä¸€ä¸”æ˜“äºç†è§£ã€‚\n",
    "\n",
    "æ€§èƒ½ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨ImageNetå›¾åƒåˆ†ç±»æŒ‘æˆ˜èµ›ä¸­å–å¾—äº†ä¼˜å¼‚æˆç»©ã€‚\n",
    "\n",
    "2.**âŒ ç¼ºç‚¹ï¼š**\n",
    "\n",
    "å‚æ•°é‡å·¨å¤§ï¼ˆVGG16çº¦æœ‰138Må‚æ•°ï¼‰ï¼Œå¯¼è‡´å­˜å‚¨å’Œæ¨ç†æˆæœ¬é«˜ã€‚\n",
    "\n",
    "è®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¸é€‚ç”¨äºèµ„æºå—é™çš„è®¾å¤‡ã€‚\n",
    "\n",
    "å¦‚æœä½ åœ¨ç ”ç©¶æ‰©æ•£æ¨¡å‹ï¼ŒVGGæœ‰æ—¶ä¹Ÿç”¨ä½œç‰¹å¾æå–å™¨æ¥è®¡ç®—æ„ŸçŸ¥æŸå¤±ï¼ˆperceptual lossï¼‰ï¼Œå› ä¸ºå®ƒåœ¨æ•æ‰å›¾åƒè¯­ä¹‰ç‰¹å¾æ–¹é¢è¡¨ç°å¾ˆå¥½ã€‚\n",
    "\n",
    "## âš™ï¸ VGGçš„æ¶æ„\n",
    "<img src=\"img/VGGæ¶æ„.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGçš„ä»£ç å®ç°\n",
    "ç”±äºVGGçš„ç½‘ç»œç»“æ„æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬é€šè¿‡åˆ†æVGGç»“æ„åä¼šå‘ç°å®ƒå®é™…ä¸Šæ˜¯ç”±è®¸å¤šç±»ä¼¼çš„â€œVGGå—â€æ„æˆï¼Œæ¯ä¸€ä¸ªâ€œVGGå—â€çš„å®ç°åˆ™ç›¸å¯¹æ¯”è¾ƒç®€å•ã€‚æœ€åä½¿ç”¨nn.Sequential()å‡½æ•°å°†è¿™äº›â€œVGGå—â€ä¸²è”èµ·æ¥ï¼Œå°±å¯ä»¥å¾—åˆ°å®Œæ•´çš„VGGç½‘ç»œã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬æ¥å®ç°VGGç½‘ç»œçš„æ„å»ºã€‚æ­¤å¤„çš„æ•°æ®åº“æ˜¯ImageNet,æˆ‘ä»¬åŒæ ·é‡‡ç”¨tiny-imagenetæ•°æ®é›†ã€‚ï¼ˆåŒAlexNetï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. å¿…è¦åº“çš„å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# è·å–å½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'),'..'))\n",
    "# å¦‚æœçˆ¶ç›®å½•ä¸åœ¨ sys.pathä¸­ï¼Œåˆ™æ·»åŠ \n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "import utils\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available()\n",
    "                      else 'mps' if torch.mps.is_available()\n",
    "                      else 'cpu')\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.å¯¼å…¥æ•°æ®åº“å¹¶è½¬æ¢ä¸ºDataLoaderæ ¼å¼\n",
    "\n",
    "åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨torchvision.transforms ä»¿ç…§åŸè®ºæ–‡å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼š\n",
    "- `Resize` å’Œ `CenterCrop`ï¼šè°ƒæ•´å›¾åƒå¤§å°ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥ã€‚\n",
    "- `ToTensor`ï¼šå°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚\n",
    "- `Normalize`ï¼šå¯¹åƒç´ å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œæœ‰åŠ©äºæ¨¡å‹æ›´å¿«æ”¶æ•›ã€‚\n",
    "- åœ¨è®­ç»ƒé›†ä¸­ç”¨ `RandomHorizontalFlip`ä½¿å¾—å›¾åƒéšæœºæ°´å¹³ç¿»è½¬ï¼Œå¢å¼ºå›¾åƒ\n",
    "\n",
    "âš ï¸ **åˆå­¦è€…æç¤º**ï¼š\n",
    "- ç¡®ä¿ `mean` å’Œ `std` å€¼ä¸é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨çš„å€¼ä¸€è‡´ã€‚\n",
    "- è¾“å…¥å›¾åƒçš„å¤§å°åº”ä¸æ¨¡å‹æœŸæœ›çš„è¾“å…¥å¤§å°åŒ¹é…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGåŸè®ºæ–‡çš„é¢„å¤„ç†æµç¨‹\n",
    "transform = {\n",
    "    'train':transforms.Compose([\n",
    "    transforms.Resize(256),                      # ç¼©æ”¾æœ€çŸ­è¾¹ä¸º256åƒç´ \n",
    "    transforms.RandomCrop(224),                  # ä¸­å¿ƒè£å‰ª224x224\n",
    "    transforms.RandomHorizontalFlip(p=0.5),      # ä»¥50%æ¦‚ç‡æ°´å¹³ç¿»è½¬\n",
    "    transforms.ToTensor(),                       # è½¬æ¢ä¸ºTensorå¹¶ç¼©æ”¾åˆ°[0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # æŒ‰ImageNetå‡å€¼å’Œæ ‡å‡†å·®å½’ä¸€åŒ–\n",
    "                         std=[0.229, 0.224, 0.225])]),\n",
    "    'val':transforms.Compose([\n",
    "    transforms.Resize(256),                      # ç¼©æ”¾æœ€çŸ­è¾¹ä¸º256åƒç´ \n",
    "    transforms.CenterCrop(224),                  # ä¸­å¿ƒè£å‰ª224x224\n",
    "    transforms.ToTensor(),                       # è½¬æ¢ä¸ºTensorå¹¶ç¼©æ”¾åˆ°[0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # æŒ‰ImageNetå‡å€¼å’Œæ ‡å‡†å·®å½’ä¸€åŒ–\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n03444034\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–éªŒè¯é›†çš„æ ‡ç­¾\n",
    "val_labels = {}\n",
    "with open('../Datasets/tiny-imagenet-200/val/val_annotations.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        filename, label = parts[0], parts[1]\n",
    "        val_labels[filename] = label\n",
    "print(val_labels['val_0.JPEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¦–å…ˆå°†è®­ç»ƒæ•°æ®é›†åŠ è½½åˆ°DataLoaderä¸­\n",
    "ImageNet_train = datasets.ImageFolder(root='../Datasets/tiny-imagenet-200/train',transform=transform['train'])\n",
    "ImageNet_train_iter = DataLoader(ImageNet_train,batch_size=64,shuffle=True,num_workers=0)\n",
    "\n",
    "# è‡ªå®šä¹‰éªŒè¯é›†æ•°æ®é›†\n",
    "class TinyImageNetValDataset(Dataset):\n",
    "    def __init__(self, img_dir, val_labels, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_dict = val_labels\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(list(set(self.img_dict.values())))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.img_list = list(self.img_dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.class_to_idx[self.img_dict[img_name]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "ImageNet_val = TinyImageNetValDataset(\n",
    "    img_dir='../Datasets/tiny-imagenet-200/val/images',\n",
    "    val_labels=val_labels,\n",
    "    transform=transform['val'])\n",
    "ImageNet_val_iter = DataLoader(ImageNet_val, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n",
      "tensor([178, 141, 140, 109, 119,  64,  18, 112,  73, 137, 187,  53, 117, 161,\n",
      "         13,  21, 155,  27, 160, 195,  89,  51, 177,  16, 133, 122,  45,  49,\n",
      "        183, 115, 152,  22, 160,  28, 183, 103,  63, 176, 187, 165,  75, 110,\n",
      "         87,  50, 161, 145,  45, 115, 186,  14, 174, 101,  63,  96, 189, 172,\n",
      "        144,  39,  25, 139, 199,  23,  29, 121])\n",
      "2\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n",
      "tensor([107, 139, 140,  69,  69, 161, 147,  73, 145,  39, 158, 188,  39, 120,\n",
      "         21,  79,  33, 165, 153, 119, 123, 124,  18,   1, 170, 141, 171, 158,\n",
      "         79,  25, 121, 179, 124, 130, 176,  86,   6, 129, 142, 127,  33,  33,\n",
      "         44,  40, 110,  40, 159, 184,  57,  80,   9,  34,  39,  14,  75, 199,\n",
      "         10,  99,  66, 160,  69, 177,  25, 101])\n"
     ]
    }
   ],
   "source": [
    "# å°è¯•è¾“å‡ºä¸¤ä¸ªDataLoaderä¸­çš„ç¬¬ä¸€æ‰¹å¼ é‡çš„å½¢çŠ¶\n",
    "img_train = next(iter(ImageNet_train_iter))\n",
    "print(len(img_train))\n",
    "print(img_train[0].shape)\n",
    "print(img_train[1].shape)\n",
    "print(img_train[1])\n",
    "\n",
    "img_val = next(iter(ImageNet_val_iter))\n",
    "print(len(img_val))\n",
    "print(img_val[0].shape)\n",
    "print(img_val[1].shape)\n",
    "print(img_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. å®šä¹‰VGGå—\n",
    "#### ğŸ” VGGå—çš„æ„å»ºè§„å¾‹\n",
    "\n",
    "1. **å·ç§¯å±‚ï¼š** æ¯ä¸ªVGGå—åŒ…å«2åˆ°3ä¸ªè¿ç»­çš„å·ç§¯å±‚ï¼Œæ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨ï¼š\n",
    "- å·ç§¯æ ¸å¤§å°ï¼š3Ã—3\n",
    "- æ­¥å¹…ï¼ˆstrideï¼‰ï¼š1\n",
    "- å¡«å……ï¼ˆpaddingï¼‰ï¼š1ï¼ˆä¿æŒç‰¹å¾å›¾å¤§å°ä¸å˜ï¼‰\n",
    "\n",
    "2. **æ¿€æ´»å‡½æ•°ï¼š** æ¯ä¸ªå·ç§¯å±‚åé¢è·Ÿä¸€ä¸ªReLUæ¿€æ´»ã€‚\n",
    "\n",
    "3. **é€šé“æ•°ï¼š** éšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œæ¯ä¸ªå—çš„è¾“å‡ºé€šé“æ•°é‡ä¾æ¬¡ä¸ºï¼š\n",
    "```css\n",
    "64 â†’ 128 â†’ 256 â†’ 512 â†’ 512\n",
    "```\n",
    "4. **æ± åŒ–å±‚ï¼š** æ¯ä¸ªVGGå—åé¢æ¥ä¸€ä¸ª2Ã—2æœ€å¤§æ± åŒ–å±‚ï¼Œæ­¥å¹…ä¸º2ï¼Œç”¨äºç‰¹å¾ä¸‹é‡‡æ ·ã€‚\n",
    "\n",
    "#### ğŸ—ï¸ VGGä¸åŒæ¶æ„çš„VGGå—é…ç½®\n",
    "| ç½‘ç»œç»“æ„   | Block1        | Block2        | Block3          | Block4          | Block5          |\n",
    "|------------|----------------|----------------|------------------|------------------|------------------|\n",
    "| **VGG11**  | 1Ã—Conv64       | 1Ã—Conv128      | 2Ã—Conv256        | 2Ã—Conv512        | 2Ã—Conv512        |\n",
    "| **VGG13**  | 2Ã—Conv64       | 2Ã—Conv128      | 2Ã—Conv256        | 2Ã—Conv512        | 2Ã—Conv512        |\n",
    "| **VGG16**  | 2Ã—Conv64       | 2Ã—Conv128      | 3Ã—Conv256        | 3Ã—Conv512        | 3Ã—Conv512        |\n",
    "| **VGG19**  | 2Ã—Conv64       | 2Ã—Conv128      | 4Ã—Conv256        | 4Ã—Conv512        | 4Ã—Conv512        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs,in_channels,out_channels):\n",
    "    \"\"\"\n",
    "    æ„å»ºVGGå—:å¤šä¸ª3*3å·ç§¯å±‚ + ReLUæ¿€æ´» + 2*2æœ€å¤§æ± åŒ–ã€‚\n",
    "    \n",
    "    Args:\n",
    "        num_convs (int): å·ç§¯å±‚æ•°é‡\n",
    "        in_channels (int): è¾“å…¥é€šé“æ•°\n",
    "        out_channels (int): è¾“å‡ºé€šé“æ•°\n",
    "    \n",
    "    Returns:\n",
    "        nn.Sequential: VGGå—\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=1,padding=1))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. æ­å»ºVGGç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "å®é™…ä¸Šæˆ‘ä»¬å®Œå…¨å¯ä»¥å®šä¹‰ä¸€ä¸ªæ¯”è¾ƒé€šç”¨çš„VGGæ¨¡å‹ï¼Œé€šè¿‡ä¸åŒçš„å‚æ•°è¾“å…¥å¯ä»¥æ„å»ºä¸åŒæ·±åº¦å’Œå¹¿åº¦çš„VGGç¥ç»ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self,conv_arch,fc_features=4096,fc_hidden_units=4096,num_classes=1000):\n",
    "        \"\"\"\n",
    "        æ„å»ºå®Œæ•´çš„VGGç½‘ç»œã€‚\n",
    "        \n",
    "        Args:\n",
    "            conv_arch (list): VGGå·ç§¯éƒ¨åˆ†çš„é…ç½®,æ¯ä¸ªå…ƒç´ ä¸º (å·ç§¯å±‚æ•°, è¾“å…¥é€šé“, è¾“å‡ºé€šé“)\n",
    "            fc_features (int): ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚çš„è¾“å…¥ç‰¹å¾æ•°\n",
    "            fc_hidden_units (int): éšè—å±‚çš„ç¥ç»å…ƒæ•°\n",
    "            num_classes (int): åˆ†ç±»ç±»åˆ«æ•°\n",
    "        \"\"\"\n",
    "        super(VGG,self).__init__()\n",
    "        \n",
    "        # è®¡ç®—å…¨è¿æ¥å±‚è¾“å…¥çš„ç‰¹å¾æ•° (æ ¹æ®å·ç§¯å±‚è¾“å‡ºçš„å°ºå¯¸)\n",
    "        self.fc_features = fc_features  # è‡ªå®šä¹‰è¾“å…¥ç‰¹å¾æ•°é‡ï¼Œå¯ä»¥æ ¹æ®å·ç§¯è¾“å‡ºå°ºå¯¸æ¥è®¡ç®—\n",
    "        self.fc_hidden_units = fc_hidden_units\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = self.make_layers(conv_arch)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(fc_features,fc_hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_hidden_units, num_classes)\n",
    "        )\n",
    "\n",
    "    def make_layers(self,conv_arch):\n",
    "        layers=[]\n",
    "        for (num_convs,in_channels,out_channels) in conv_arch:\n",
    "            layers.append(vgg_block(num_convs,in_channels,out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "net = VGG([(1, 3, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512)]).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š VGGä¸åŒæ¶æ„çš„é…ç½® (å‘½åçš„æ¥æºæ˜¯å·ç§¯å±‚æ•°+å…¨è¿æ¥å±‚æ•°)\n",
    "vgg11_arch = [(1, 3, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512)]\n",
    "vgg13_arch = [(2, 3, 64), (2, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512)]\n",
    "vgg16_arch = [(2, 3, 64), (2, 64, 128), (3, 128, 256), (3, 256, 512), (3, 512, 512)]\n",
    "vgg19_arch = [(2, 3, 64), (2, 64, 128), (4, 128, 256), (4, 256, 512), (4, 512, 512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG11 è¾“å‡ºå½¢çŠ¶: torch.Size([1, 1000])\n",
      "VGG13 è¾“å‡ºå½¢çŠ¶: torch.Size([1, 1000])\n",
      "VGG16 è¾“å‡ºå½¢çŠ¶: torch.Size([1, 1000])\n",
      "VGG19 è¾“å‡ºå½¢çŠ¶: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# ğŸƒâ€â™‚ï¸ **æµ‹è¯•ä¸åŒVGGæ¨¡å‹**\n",
    "def test_vgg(arch, name):\n",
    "    model = VGG(arch,fc_features=512*7*7)\n",
    "    X = torch.randn(1, 3, 224, 224)  # æ¨¡æ‹Ÿè¾“å…¥\n",
    "    output = model(X)\n",
    "    print(f\"{name} è¾“å‡ºå½¢çŠ¶: {output.shape}\")  # æœŸæœ›è¾“å‡º: torch.Size([1, 1000])\n",
    "\n",
    "\n",
    "\n",
    "test_vgg(vgg11_arch, \"VGG11\")\n",
    "test_vgg(vgg13_arch, \"VGG13\")\n",
    "test_vgg(vgg16_arch, \"VGG16\")\n",
    "test_vgg(vgg19_arch, \"VGG19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ç”¨VGG11æ¥è®­ç»ƒï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnet = VGG(vgg11_arch,fc_features=512*7*7,num_classes=200).to(device)\\nloss_fn = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(params=net.parameters(),lr=0.001)\\nutils.training_loop(net,loss_fn=loss_fn,optimizer=optimizer,train_iter=ImageNet_train_iter,test_iter=ImageNet_val_iter,epochs=15,device=device)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "net = VGG(vgg11_arch,fc_features=512*7*7,num_classes=200).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(),lr=0.001)\n",
    "utils.training_loop(net,loss_fn=loss_fn,optimizer=optimizer,train_iter=ImageNet_train_iter,test_iter=ImageNet_val_iter,epochs=15,device=device)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
