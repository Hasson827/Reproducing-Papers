{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 背后的数学\n",
    "\n",
    "## 符号统一\n",
    "\n",
    "- $x_{t}$ 表示在时间步 $t$ 时的图像，其中 $x_{0}$ 表示原始图像，而最终遵循各向同性高斯分布的最终图像被称为 $x_{T}$\n",
    "- $q(x_{t}|x_{t-1})$ 对应于前向过程，其输出图像是在输入图像的基础上叠加了一些小噪声。\n",
    "- $p(x_{t-1}|x_{t})$ 对应于反向扩散过程，它以 $x_{t}$ 为输入，并使用神经网络生成样本 $x_{t-1}$\n",
    "\n",
    "## 前向过程\n",
    "\n",
    "$$\n",
    "q(x_{t}|x_{t-1}) = \\mathcal{N}(x_{t},\\sqrt{1-\\beta_{t}}\\,x_{t-1},\\beta_{t}I)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $\\mathcal{N}$ 是正态分布\n",
    "- $x_{t}$ 是输出\n",
    "- $\\sqrt{1-\\beta_{t}}x_{t-1}$ 是平均值，也可以记为 $\\mu_{t}$\n",
    "- $\\beta_{t}I$ 是方差，也可以记为 $\\sigma_{t}^{2}$\n",
    "- $\\beta$ 是调度器，$\\forall \\beta \\,,\\, \\beta \\in (0,1) $\n",
    "\n",
    "现在我们已经知道了前向过程中一步的公式，理论上只要将这个步骤重复1000次就可以得到结果，但是有一种更简单的方法，只用了一步就解决了。\n",
    "\n",
    "首先我们新定义两个新变量\n",
    "\n",
    "$$\n",
    "\\alpha_{t} = 1-\\beta_{t}\n",
    "\\\\[10pt]\n",
    "\\overline\\alpha_{t} = \\prod_{s=1}^{t}\\alpha_{s}\n",
    "$$\n",
    "\n",
    "然后我们可以利用重参数化技巧，也就是 $\\mathcal{N}(\\mu,\\sigma^{2}) = \\mu + \\sigma\\cdot\\epsilon$ 来重写 $q(x_{t}|x_{t-1})$，其中 $\\epsilon \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "$$\n",
    "q(x_{t}|x_{t-1}) = \\mathcal{N}(x_{t},\\sqrt{1-\\beta_{t}}\\,x_{t-1},\\beta_{t}I)\n",
    "\\\\[10pt]\n",
    "= \\sqrt{1-\\beta_{t}}\\,x_{t-1}\\,+\\,\\sqrt{\\beta_{t}}\\,\\epsilon\n",
    "\\\\[10pt]\n",
    "= \\sqrt{\\alpha_{t}}x_{t-1} \\,+\\, \\sqrt{1-\\alpha_{t}}\\,\\epsilon\n",
    "$$\n",
    "\n",
    "再将 $q(x_{t-1}|x_{t-2})$ 以类似的形式写出来，在上式中将 $x_{t-1}$ 替换为 $x_{t-2}$ 的表达式，可得：\n",
    "\n",
    "$$\n",
    "q(x_{t}|x_{t-1}) = \\sqrt{\\alpha_{t}}x_{t-1} \\,+\\, \\sqrt{1-\\alpha_{t}}\\,\\epsilon\n",
    "\\\\[10pt]\n",
    "= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} \\,+\\, \\sqrt{1-\\alpha_{t}\\alpha_{t-1}}\\,\\epsilon\n",
    "\\\\[10pt]\n",
    "= \\sqrt{\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}}x_{t-3} \\,+\\, \\sqrt{1-\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}}\\,\\epsilon\n",
    "\\\\[10pt]\n",
    "···\n",
    "$$\n",
    "\n",
    "如此反复迭代，最终可以得到 $x_{t}$ 和 $x_{0}$ 之间的关系：\n",
    "\n",
    "$$\n",
    "q(x_{t}|x_{0}) = \\sqrt{\\overline\\alpha_{t}}x_{0} \\,+\\, \\sqrt{1-\\overline\\alpha_{t}}\\,\\epsilon\n",
    "\\,\\sim\\, \\mathcal{N}(x_{t},\\sqrt{\\overline\\alpha_{t}}x_{0},(1-\\overline\\alpha_{t})I)\n",
    "$$\n",
    "\n",
    "## 反向扩散过程\n",
    "\n",
    "$$\n",
    "p(x_{t-1}|x_{t}) = \\mathcal{N}(x_{t-1},\\mu_{\\theta}(x_{t},t),\\Sigma_{\\theta}(x_{t},t))\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $\\mathcal{N}$ 是正态分布\n",
    "- $x_{t-1}$ 是输出\n",
    "- $\\Sigma_{\\theta}$ 是网络本应该学习的方差参数，但是此处我们将其设定为一个固定的值，因而不对其进行学习\n",
    "- $\\mu_{\\theta}$ 是网络需要学习的均值参数\n",
    "\n",
    "## 损失函数\n",
    "\n",
    "理论上的损失函数应该是一个负对数似然函数\n",
    "\n",
    "$$\n",
    "-\\log{p_{\\theta}(x_{0})}\n",
    "$$\n",
    "\n",
    "但是 $x_{0}$ 的概率很难计算，因为它取决于 $x_{0}$ 之前所有的时间步的输入，即 $x_{1:T}$\n",
    "\n",
    "因此我们决定计算该函数的变分下界，即\n",
    "\n",
    "$$\n",
    "-\\log{p_{\\theta}(x_{0})} \\le -\\log{p_{\\theta}(x_{0})} \\,+\\, D_{KL}(q(x_{1:T}|x_{0})||p_{\\theta}(x_{1:T}|x_{0}))\n",
    "$$\n",
    "\n",
    "KL散度是衡量两个分布相似程度的指标，并且始终为非负数。\n",
    "\n",
    "对于两个单一变量的高斯分步 $p\\sim\\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $q\\sim\\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$ 而言，他们的KL散度为：\n",
    "\n",
    "$$\n",
    "D_{KL}(p||q) = \\log(\\frac{\\sigma_{2}}{\\sigma_{1}})\\,+\\,\\frac{\\sigma_{1}^{2}+(\\mu_{1}-\\mu_{2})^{2}}{2\\sigma_{2}^{2}}\\,-\\,\\frac{1}{2}\n",
    "$$\n",
    "\n",
    "在模型优化中，KL散度常作为损失函数，引导模型 $q$ 逼近真实分布 $p$ 。例如，变分自编码器（VAE）中用它约束潜在变量的分布。\n",
    "\n",
    "下面开始推导为什么加上KL散度之后能够使得计算更加方便\n",
    "\n",
    "- 我们可以将KL散度公式变为以下形式：\n",
    "\n",
    "$$\n",
    "D_{KL}(q(x_{1:T}|x_{0})||p_{\\theta}(x_{1:T}|x_{0})) = \\log\\left( \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{1:T}|x_{0})} \\right)\n",
    "$$\n",
    "\n",
    "- 对数中的分母可以利用贝叶斯公式变为以下形式：\n",
    "\n",
    "$$\n",
    "p_{\\theta}(x_{1:T}|x_{0}) = \\frac{p_{\\theta}(x_{0}|x_{1:T})p_{\\theta}(x_{1:T})}{p_{\\theta}(x_{0})}\n",
    "$$\n",
    "\n",
    "- 而这个贝叶斯公式中的分子又可以由全概率公式合并为：\n",
    "\n",
    "$$\n",
    "p_{\\theta}(x_{0}|x_{1:T})p_{\\theta}(x_{1:T}) = p_{\\theta}(x_{0},x_{1:T}) = p_{\\theta}(x_{0:T})\n",
    "$$\n",
    "\n",
    "- 所以原来的对数形式就可以写成：\n",
    "\n",
    "$$\n",
    "\\log\\left( \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{1:T}|x_{0})} \\right) = \\log\\left( \\frac{q(x_{1:T}|x_{0})}{\\frac{p_{\\theta}(x_{0:T})}{p_{\\theta}(x_{0})}} \\right) = \\log\\left( \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})} \\right) + \\log\\left( p_{\\theta}(x_{0}) \\right)\n",
    "$$\n",
    "\n",
    "- 因此它和原本的 $-\\log\\left( p_{\\theta}(x_{0}) \\right)$相互抵消，最终损失函数变为\n",
    "\n",
    "$$\n",
    "\\log\\left( \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})} \\right)\n",
    "$$\n",
    "\n",
    "还没有结束！这个函数实际上看着还是十分复杂，我们对它进行进一步处理：\n",
    "\n",
    "- 我们对对数中的分子分母都根据其定义进行展开，可以得到：\n",
    "\n",
    "$$\n",
    "\\log\\left( \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})} \\right)\n",
    "= \\log\\left( \\frac{\\textstyle \\prod_{t=1}^{T}q(x_{t}|x_{t-1})}{p(x_{T})\\textstyle \\prod_{t=1}^{T}p_{\\theta}(x_{t-1}|x_{t})} \\right)\n",
    "= \\log\\left( \\frac{\\textstyle \\prod_{t=1}^{T}q(x_{t}|x_{t-1})}{\\textstyle \\prod_{t=1}^{T}p_{\\theta}(x_{t-1}|x_{t})} \\right)-\\log \\left( p(x_{T}) \\right)\n",
    "$$\n",
    "\n",
    "- 利用对数性质，将 $\\prod$ 移到对数外变成 $\\sum$\n",
    "\n",
    "$$\n",
    "原式 = \\sum_{t=1}^{T}\\log \\left( \\frac{q(x_{t}|x_{t-1})}{p_{\\theta}(x_{t-1}|x_{t})} \\right) - \\log \\left( p(x_{T}) \\right)\n",
    "= \\sum_{t=2}^{T}\\log \\left( \\frac{q(x_{t}|x_{t-1})}{p_{\\theta}(x_{t-1}|x_{t})} \\right)+ \\log\\left( \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right) - \\log \\left( p(x_{T}) \\right)\n",
    "$$\n",
    "\n",
    "- 利用贝叶斯公式，将 $\\sum$ 中所有的分子都该写成如下形式：\n",
    "\n",
    "$$\n",
    "q(x_{t}|x_{t-1}) = \\frac{q(x_{t-1}|x_{t})q(x_{t})}{q(x_{t-1})} = \\frac{q(x_{t-1}|x_{t},x_{0})q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})}\n",
    "$$\n",
    "\n",
    "- 那么再代回原式后得到：\n",
    "\n",
    "$$\n",
    "原式 = \\sum_{t=2}^{T}\\log \\left( \\frac{q(x_{t-1}|x_{t},x_{0})q(x_{t}|x_{0})}{p_{\\theta}(x_{t-1}|x_{t})q(x_{t-1}|x_{0})} \\right)+ \\log\\left( \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right) - \\log \\left( p(x_{T}) \\right)\n",
    "$$\n",
    "\n",
    "- 我们将 $\\sum$ 中的log函数拆开得到\n",
    "\n",
    "$$\n",
    "原式 = \\sum_{t=2}^{T}\\log \\left( \\frac{q(x_{t-1}|x_{t},x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} \\right) + \\sum_{t=2}^{T}\\log \\left( \\frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})} \\right) + \\log\\left( \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right) - \\log \\left( p(x_{T}) \\right)\n",
    "$$\n",
    "\n",
    "- 第二个 $\\sum$ 中的式子展开后，中间项会全部抵消，最后留下：\n",
    "\n",
    "$$\n",
    "原式 = \\sum_{t=2}^{T}\\log \\left( \\frac{q(x_{t-1}|x_{t},x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} \\right) + \\log\\left( \\frac{q(x_{T}|x_{0})}{q(x_{1}|x_{0})} \\right) + \\log\\left( \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right) - \\log \\left( p(x_{T}) \\right)\n",
    "$$\n",
    "\n",
    "- 二、三两项消去并把第四项代入分母，原本第三项分母提出可得到\n",
    "\n",
    "$$\n",
    "原式 = \\sum_{t=2}^{T}\\log \\left( \\frac{q(x_{t-1}|x_{t},x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} \\right) + \\log\\left( \\frac{q(x_{T}|x_{0})}{p(x_{T })} \\right) - \\log(p_{\\theta}(x_{0}|x_{1}))\n",
    "$$\n",
    "\n",
    "- 我们能够将第一项和第二项都看作KL散度，即\n",
    "\n",
    "$$\n",
    "原式 = \\sum_{t=2}^{T}D_{KL}(q(x_{t-1}|x_{t},x_{0})||p_{\\theta}(x_{t-1}|x_{t})) + D_{KL}(q(x_{T}|x_{0})||p(x_{T})) - \\log(p_{\\theta}(x_{0}|x_{1}))\n",
    "$$\n",
    "\n",
    "- 而由于 $q$ 只是一个前向传播过程且 $p(x_{T})$ 只是一个服从高斯正太分布的随机分布，几乎没有可以学习的参数，所以第二项是一个很小的量，完全可以被忽略。\n",
    "- 我们知道 $q$ 和 $p$ 都服从正态分布，且正态分布中的方差被固定为 $\\beta I$ ，因此我们可以得到以下等式；\n",
    "\n",
    "$$\n",
    "p(x_{t-1}|x_{t}) \\sim \\mathcal{N}(x_{t-1},\\mu_{\\theta}(x_{t},t),\\beta I)\n",
    "\\\\\n",
    "q(x_{t-1}|x_{t},x_{0}) \\sim \\mathcal{N}(x_{t-1},\\tilde\\mu_{t}(x_{t},x_{0}),\\tilde\\beta_{t} I)\n",
    "$$\n",
    "\n",
    "其中\n",
    "$$\n",
    "\\tilde\\mu_{t}(x_{t},x_{0}) = \\frac{\\sqrt{\\alpha_{t}}\\,(1-\\overline \\alpha_{t-1})}{1-\\overline \\alpha_{t}}x_{t} + \\frac{\\sqrt{\\overline\\alpha_{t-1}}\\beta_{t}}{1-\\overline\\alpha_{t}}x_{0}\n",
    "$$\n",
    "\n",
    "- 由前文中得到的 $x_{t} = \\sqrt{\\overline\\alpha_{t}}x_{0} \\,+\\, \\sqrt{1-\\overline\\alpha_{t}}\\,\\epsilon$ 可以反推得到 $x_{0} = \\frac{1}{\\sqrt{\\overline\\alpha_{t}}}(x_{t}-\\sqrt{1-\\overline\\alpha_{t}}\\epsilon)$ ，将其带入原式，最终可得：\n",
    "\n",
    "$$\n",
    "\\tilde\\mu_{t} = \\frac{1}{\\sqrt{\\alpha_{t}}}(x_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\overline\\alpha_{t}}}\\epsilon)\n",
    "$$\n",
    "\n",
    "- 作者决定采用两个均值之间的均方误差作为损失函数，也就是\n",
    "\n",
    "$$\n",
    "L_{t} = \\frac{1}{2\\sigma_{t}^{2}}\\left| \\tilde\\mu_{t}(x_{t},x_{0}) - \\mu_{\\theta}(x_{t},t) \\right| ^{2}\n",
    "$$\n",
    "\n",
    "- 而 $\\tilde\\mu_{t}$ 和 $\\mu_{\\theta}$ 两个式子除了一个 $\\epsilon$ 和 $\\epsilon_{\\theta}$ 的区别之外完全相同，并且作者通过实验发现省略前面的系数实际上训练效果更好，所以损失函数实际上可以化简为预测 $\\epsilon$ ，也就是噪声，即\n",
    "\n",
    "$$\n",
    "L_{t} = \\left| \\epsilon - \\epsilon_{\\theta}(x_{t},t ) \\right| ^{2}\n",
    "$$\n",
    "\n",
    "- 最后，再把 $x_{t}$ 用 $x_{0}$ 表示，我们能够得到：\n",
    "\n",
    "$$\n",
    "L_{t} = \\left| \\epsilon - \\epsilon_{\\theta}(\\sqrt{\\overline\\alpha_{t}}x_{0} + \\sqrt{1-\\overline\\alpha_{t}}\\epsilon\\,,t ) \\right| ^{2}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现\n",
    "\n",
    "简而言之，我们从数据中获取图像并逐步添加噪点。然后，我们训练一个模型来预测每个步骤的噪声，并使用该模型生成图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() \n",
    "                      else 'mps' if torch.mps.is_available()\n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title=\"\"):\n",
    "    \"\"\"把给定的图片以方形网格的形式显示出来\"\"\"\n",
    "    images = [np.clip(im.permute(1,2,0).numpy(), 0, 1) for im in images]\n",
    "    \n",
    "    # 定义行数和列数\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    rows = int(len(images)**0.5)\n",
    "    cols = round(len(images)/rows)\n",
    "    \n",
    "    # 在网格中显示图片\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fig.add_subplot(rows,cols,idx + 1)\n",
    "            \n",
    "            if idx < len(images):\n",
    "                plt.imshow(images[idx])\n",
    "                plt.axis('off')\n",
    "                idx += 1\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet构建\n",
    "下面是对代码各个部分的详细说明：\n",
    "\n",
    "这个代码实现了 UNet 网络的核心组件，用于图像分割等计算机视觉任务。首先，代码定义了一个名为 `double_conv` 的类，该类执行连续两次卷积操作。在每次卷积之后，都使用了批归一化 (`BatchNorm2d`) 和 ReLU 激活函数，这样可以提高网络的训练稳定性及非线性感知能力。\n",
    "\n",
    "接着，`down_layer` 类实现了下采样操作。它首先使用最大池化 (`nn.MaxPool2d`) 将输入特征图的分辨率减半，然后调用 `double_conv` 对池化后的特征图进行卷积处理，以便提取更深层次的特征信息。这种结构在典型的编码器-解码器架构中十分常见，用来逐步压缩空间信息并增加通道特征。\n",
    "\n",
    "在上采样路径中，`up` 类负责将低分辨率的特征图通过转置卷积 (`nn.ConvTranspose2d`) 的方式进行上采样。由于上采样后可能与跳跃连接（来自编码器同层特征）的尺寸不匹配，因此采用 `F.pad` 对特征图进行适当填充，使得后续使用 `torch.cat` 在通道维度上进行拼接成为可能。这样可以充分利用编码器过程中的细粒度信息，有助于提高解码器的重构效果。\n",
    "\n",
    "基于 `up` 类，`up_layer` 类首先利用上采样操作获得尺寸匹配的特征图，然后跟跳跃连接得到的特征图进行拼接，最后通过 `double_conv` 进一步融合信息。这种设计允许网络在解码阶段逐步恢复空间信息，并利用编码器中的高分辨率细节。\n",
    "\n",
    "UNet 类将上述各个模块组合成一个整体架构。编码器部分依次由几层 `double_conv` 和 `down_layer` 构成，每经过一层，下采样使特征图尺寸减小而通道数增多。解码器部分则利用 `up_layer` 逐步上采样，同时通过跳跃连接将前面的特征图与当前上采样特征图进行融合，并最终由最后的卷积层 (`nn.Conv2d`) 输出与输入相同尺寸的结果。\n",
    "\n",
    "此外，UNet 还引入了时间嵌入（time embedding）的概念。通过一个嵌入层 (`nn.Embedding`) 生成正弦余弦嵌入（利用 `sinusoidal_embedding` 函数），然后将这些嵌入值经过一系列全连接层（由 `_make_te` 生成的模块）调整维度后，分别加到各个卷积模块的输入上。这种设计常见于时间条件生成模型中，用以引入额外时间信息从而影响输出。\n",
    "\n",
    "最后，代码中还展示了一些辅助函数，如 `requires_grad_` 用于控制模块参数是否参与梯度计算，以及一个简单的 `super` 类的重载声明，展示了构造函数可接受不同参数形式。这些细节共同构成了一个灵活且功能丰富的网络架构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间嵌入（time embedding）主要用于将时间步信息引入网络中，从而让模型在不同的时间步（例如扩散过程中的不同阶段）下能够学习和调整其特征提取和生成过程。在这段代码中，时间嵌入具体发挥如下作用：\n",
    "\n",
    "- **条件控制：** 通过将时间步 t 转换为一个嵌入向量，网络能够“知道”当前正处于扩散过程中的哪个阶段，进而根据不同的 t 调整各层输出。这对于像 DDPM 这样的扩散模型尤为重要，因为模型需要针对不同的噪声水平做出不同的处理。\n",
    "\n",
    "- **信息融合：** 时间嵌入经过一系列全连接层（通过 _make_te 创建）后，其维度与对应卷积层的输入或输出匹配，并通过 reshape 后加到特征图上。这样，不仅在整个网络的编码和解码过程中将时间信息传递下去，而且使网络在每个阶段都能灵活利用时间信息来调节特征变化。\n",
    "\n",
    "- **对抗噪声：** 在训练过程中，不同时间步对应不同的噪声程度，利用时间嵌入可以使网络在处理不同噪声条件时更加稳定，从而提高生成图像的质量。 \n",
    "\n",
    "总结来说，时间嵌入使模型具备条件生成能力，能够根据扩散过程中当前的步数或噪声水平来调整内部特征，促进在整个降噪或生成过程中达到更好的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  sinusoidal_embedding(n,d):\n",
    "    \"\"\"生成正弦余弦嵌入\"\"\"\n",
    "    embedding = torch.tensor([[i / 10000**(2*j/d) for j in range(d)] for i in range(n)])\n",
    "    sin_mask = torch.arange(0,n,2)\n",
    "    embedding[sin_mask] = torch.sin(embedding[sin_mask])\n",
    "    embedding[1-sin_mask] = torch.cos(embedding[1-sin_mask])\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,out_ch,3,padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch,out_ch,3,padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class down_layer(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2,stride=2,padding=0)\n",
    "        self.conv = double_conv(in_ch,out_ch)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super().__init__()\n",
    "        self.up_scale = nn.ConvTranspose2d(in_ch,out_ch,2,stride=2)\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        x2 = self.up_scale(x2)\n",
    "        diffY = x1.size()[2] - x2.size()[2]\n",
    "        diffX = x1.size()[3] - x2.size()[3]\n",
    "        \n",
    "        x2 = F.pad(x2, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2,x1],dim=1)\n",
    "        return x\n",
    "\n",
    "class up_layer(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super().__init__()\n",
    "        self.up = up(in_ch,out_ch)\n",
    "        self.conv = double_conv(in_ch,out_ch)\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        a = self.up(x1,x2)\n",
    "        x = self.conv(a)\n",
    "        return x\n",
    "        \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,in_channels=1,n_steps=1000,time_emb_dim=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = double_conv(in_channels,64)\n",
    "        self.down1 = down_layer(64,128)\n",
    "        self.down2 = down_layer(128,256)\n",
    "        self.down3 = down_layer(256,512)\n",
    "        self.down4 = down_layer(512,1024)\n",
    "        self.up1 = up_layer(1024,512)\n",
    "        self.up2 = up_layer(512,256)\n",
    "        self.up3 = up_layer(256,128)\n",
    "        self.up4 = up_layer(128,64)\n",
    "        self.last_conv = nn.Conv2d(64,in_channels,1)\n",
    "        \n",
    "        # TIme embedding\n",
    "        self.time_embed = nn.Embedding(n_steps,time_emb_dim)\n",
    "        self.time_embed.weight.data = sinusoidal_embedding(n_steps,time_emb_dim)\n",
    "        self.time_embed.requires_grad_(False)\n",
    "        self.te1 = self._make_te(time_emb_dim,in_channels)\n",
    "        self.te2 = self._make_te(time_emb_dim,64)\n",
    "        self.te3 = self._make_te(time_emb_dim,128)\n",
    "        self.te4 = self._make_te(time_emb_dim,256)\n",
    "        self.te5 = self._make_te(time_emb_dim,512)\n",
    "        self.te1_up = self._make_te(time_emb_dim,1024)\n",
    "        self.te2_up = self._make_te(time_emb_dim,512)\n",
    "        self.te3_up = self._make_te(time_emb_dim,256)\n",
    "        self.te4_up = self._make_te(time_emb_dim,128)\n",
    "        \n",
    "    def _make_te(self,dim_in,dim_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(dim_in,dim_out),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim_out,dim_out),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x,t):\n",
    "        bs = x.shape[0]\n",
    "        t = self.time_embed(t)\n",
    "        x1 = self.conv1(x+self.te1(t).reshape(bs,-1,1,1))\n",
    "        x2 = self.down1(x1+self.te2(t).reshape(bs,-1,1,1))\n",
    "        x3 = self.down2(x2+self.te3(t).reshape(bs,-1,1,1))\n",
    "        x4 = self.down3(x3+self.te4(t).reshape(bs,-1,1,1))\n",
    "        x5 = self.down4(x4+self.te5(t).reshape(bs,-1,1,1))\n",
    "        x1_up = self.up1(x4,x5+self.te1_up(t).reshape(bs,-1,1,1))\n",
    "        x2_up = self.up2(x3,x1_up+self.te2_up(t).reshape(bs,-1,1,1))\n",
    "        x3_up = self.up3(x2,x2_up+self.te3_up(t).reshape(bs,-1,1,1))\n",
    "        x4_up = self.up4(x1,x3_up+self.te4_up(t).reshape(bs,-1,1,1))\n",
    "        output = self.last_conv(x4_up)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "x = torch.randn(bs,1,256,256)\n",
    "n_steps = 1000\n",
    "timesteps = torch.randint(0,n_steps,(bs,)).long()\n",
    "unet = UNet()\n",
    "y = unet(x,timesteps)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self,network,num_timesteps,beta_start=1e-4,beta_end=2e-2,device=device) -> None:\n",
    "        super().__init__()\n",
    "        self.betas = torch.linspace(beta_start,beta_end,num_timesteps,dtype=torch.float32).to(device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas,dim=0)\n",
    "        self.network = network\n",
    "        self.device = device\n",
    "        self.sqrt_alphas_cumprod = self.alphas_cumprod**0.5\n",
    "        self.sqrt_one_minus_alphas_cumprod = (1-self.alphas_cumprod)**0.5\n",
    "        \n",
    "    def add_noise(self,x_start,x_noise,timesteps):\n",
    "        s1 = self.sqrt_alphas_cumprod[timesteps]\n",
    "        s2 = self.sqrt_one_minus_alphas_cumprod[timesteps]\n",
    "        s1 = s1.reshape(-1,1,1,1)\n",
    "        s2 = s2.reshape(-1,1,1,1)\n",
    "        return s1 * x_start + s2 * x_noise\n",
    "    \n",
    "    def reverse(self,x,t):\n",
    "        return self.network(x,t)\n",
    "    \n",
    "    def step(self,model_output,timestep,sample):\n",
    "        t = timestep\n",
    "        coef_epsilon = (1-self.alphas)/self.sqrt_one_minus_alphas_cumprod\n",
    "        coef_eps_t = coef_epsilon[t].reshape(-1,1,1,1)\n",
    "        coef_first = 1/self.alphas ** 0.5\n",
    "        coef_first_t = coef_first[t].reshape(-1,1,1,1)\n",
    "        pred_prev_sample = coef_first_t*(sample-coef_eps_t*model_output)\n",
    "        \n",
    "        variance = 0\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(model_output).to(self.device)\n",
    "            variance = ((self.betas[t]**0.5)*noise)\n",
    "        \n",
    "        pred_prev_sample = pred_prev_sample + variance\n",
    "        return pred_prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device):\n",
    "    \"\"\"Training loop for DDPM\"\"\"\n",
    "\n",
    "    global_step = 0\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(dataloader))\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            batch = batch[0].to(device)\n",
    "            noise = torch.randn(batch.shape).to(device)\n",
    "            timesteps = torch.randint(0, num_timesteps, (batch.shape[0],)).long().to(device)\n",
    "\n",
    "            noisy = model.add_noise(batch, noise, timesteps)\n",
    "            noise_pred = model.reverse(noisy, timesteps)\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
    "            losses.append(loss.detach().item())\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            global_step += 1\n",
    "        \n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data/'\n",
    "transforms01 = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "dataset = torchvision.datasets.CIFAR10(root=root_dir, train=True, transform=transforms01, download=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=512, shuffle=True,num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloader:\n",
    "    batch = b[0]\n",
    "    break\n",
    "bn = [b for b in batch[:100]]\n",
    "show_images(bn,\"origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "num_epochs = 15\n",
    "num_timesteps = 1000\n",
    "network = UNet(in_channels=3)\n",
    "network.to(device)\n",
    "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(ddpm, sample_size, channel, size):\n",
    "    \"\"\"从高斯噪声生成图像\"\"\"\n",
    "\n",
    "    frames = []\n",
    "    frames_mid = []\n",
    "    ddpm.eval()\n",
    "    with torch.no_grad():\n",
    "        timesteps = list(range(ddpm.num_timesteps))[::-1]\n",
    "        sample = torch.randn(sample_size, channel, size, size).to(device)\n",
    "        \n",
    "        for i, t in enumerate(tqdm(timesteps)):\n",
    "            time_tensor = (torch.ones(sample_size) * t).long().to(device)\n",
    "            residual = ddpm.reverse(sample, time_tensor).to(device)\n",
    "            sample = ddpm.step(residual, time_tensor[0], sample)\n",
    "\n",
    "            if t==500:\n",
    "                #sample_squeezed = torch.squeeze(sample)\n",
    "                for i in range(sample_size):\n",
    "                    frames_mid.append(sample[i].detach().cpu())\n",
    "\n",
    "        #sample = torch.squeeze(sample)\n",
    "        for i in range(sample_size):\n",
    "            frames.append(sample[i].detach().cpu())\n",
    "    return frames, frames_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated, generated_mid = generate_image(model, 100, 3, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(generated_mid, \"Mid result\")\n",
    "show_images(generated, \"Final result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(dataset, class_name ='ship'):\n",
    "    s_indices = []\n",
    "    s_idx = dataset.class_to_idx[class_name]\n",
    "    for i in range(len(dataset)):\n",
    "        current_class = dataset[i][1]\n",
    "        if current_class == s_idx:\n",
    "            s_indices.append(i)\n",
    "    s_dataset = Subset(dataset, s_indices)\n",
    "    return torch.utils.data.DataLoader(dataset=s_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dataloader = make_dataloader(dataset)\n",
    "ship_network = copy.deepcopy(network)\n",
    "ship_model = DDPM(ship_network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
    "num_epochs = 10\n",
    "num_timesteps = model.num_timesteps\n",
    "learning_rate = 3e-4\n",
    "ship_model.train()\n",
    "optimizer = torch.optim.Adam(ship_model.parameters(), lr=learning_rate)\n",
    "training_loop(ship_model, ship_dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
    "generated, generated_mid = generate_image(ship_model, 100, 3, 32)\n",
    "show_images(generated, \"Generated ships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_dataloader = make_dataloader(dataset, 'horse')\n",
    "horse_network = copy.deepcopy(network)\n",
    "horse_model = DDPM(horse_network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
    "num_epochs = 10\n",
    "num_timesteps = model.num_timesteps\n",
    "learning_rate = 3e-4\n",
    "horse_model.train()\n",
    "optimizer = torch.optim.Adam(horse_model.parameters(), lr=learning_rate)\n",
    "training_loop(horse_model, horse_dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
    "generated, generated_mid = generate_image(horse_model, 100, 3, 32)\n",
    "show_images(generated, \"Generated horses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truck_dataloader = make_dataloader(dataset, 'truck')\n",
    "truck_network = copy.deepcopy(network)\n",
    "truck_model = DDPM(truck_network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
    "num_epochs = 10\n",
    "num_timesteps = model.num_timesteps\n",
    "learning_rate = 3e-4\n",
    "truck_model.train()\n",
    "optimizer = torch.optim.Adam(truck_model.parameters(), lr=learning_rate)\n",
    "training_loop(truck_model, truck_dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
    "generated, generated_mid = generate_image(truck_model, 100, 3, 32)\n",
    "show_images(generated, \"Generated trucks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
