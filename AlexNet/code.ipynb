{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNetè®ºæ–‡å¤ç°\n",
    "è¿™æ˜¯ç¬¬ä¸€ä¸ªéå¸¸æˆåŠŸçš„ç”¨äºå›¾åƒåˆ†ç±»çš„ CNNï¼Œå®ƒå¯¼è‡´äº†æ·±åº¦å­¦ä¹ çƒ­æ½®çš„çˆ†å‘ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸä½¿ç”¨ dropout å±‚çš„ä¾‹å­ã€‚\n",
    "\n",
    "æ­¤å®ç°ä½¿ç”¨ ILSVRC 2012 æ•°æ®é›†ï¼Œä¹Ÿç§°ä¸ºâ€œImageNet 2012 æ•°æ®é›†â€ã€‚æ•°æ®é‡å·¨å¤§ï¼ˆ138Gï¼ï¼‰ï¼Œä½†ä¸ºäº†æˆåŠŸè®­ç»ƒ AlexNetï¼Œéœ€è¦è¿™æ ·å¤§è§„æ¨¡çš„æ•°æ®é›†ã€‚ç”±äº Tiny ImageNet æˆ– MNIST çš„ç‰¹å¾å°ºå¯¸è¾ƒå°ï¼ˆå›¾åƒæ— æ³•é€‚åº”è¾“å…¥å°ºå¯¸ 227 x 227ï¼‰ï¼Œå› æ­¤æ— æ³•è¿›è¡Œæµ‹è¯•ã€‚\n",
    "\n",
    "## åŸºæœ¬æ¶æ„\n",
    "<img src='img/AlexNet.png'>\n",
    "\n",
    "## å…³é”®ç‰¹ç‚¹\n",
    "\n",
    "1. **å…± 8 å±‚ï¼š5 å±‚å·ç§¯å±‚ + 3 å±‚å…¨è¿æ¥å±‚**\n",
    "    - ç›¸è¾ƒäºä¹‹å‰çš„LeNetæ›´æ·±ã€æ›´å¤æ‚\n",
    "\n",
    "2. **ReLU æ¿€æ´»å‡½æ•°**\n",
    "    - ä½¿ç”¨ ReLU æ›¿ä»£ Sigmoid/Tanhï¼Œæé«˜è®­ç»ƒé€Ÿåº¦ï¼Œå‡å°‘æ¢¯åº¦æ¶ˆå¤±é—®é¢˜\n",
    "\n",
    "3. **å·ç§¯å±‚ä¸æœ€å¤§æ± åŒ–å±‚**\n",
    "    - å·ç§¯å±‚ç”¨äºæå–ç‰¹å¾\n",
    "    - æœ€å¤§æ± åŒ– (Max Pooling) å±‚å‡å°‘ç©ºé—´å°ºå¯¸å’Œè¿‡æ‹Ÿåˆ\n",
    "\n",
    "4. **å±€éƒ¨å“åº”å½’ä¸€åŒ– (LRN)**\n",
    "    - å¼ºåŒ–å“åº”è¾ƒå¼ºçš„ç¥ç»å…ƒ\n",
    "    - æé«˜æ³›åŒ–èƒ½åŠ›æå‡æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "5. **ä½¿ç”¨ Dropout**\n",
    "    - åœ¨å…¨è¿æ¥å±‚ä½¿ç”¨ Dropout å‡å°‘è¿‡æ‹Ÿåˆ\n",
    "    - éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒï¼Œå¢å¼ºæ¨¡å‹é²æ£’æ€§\n",
    "\n",
    "6. **æ•°æ®å¢å¼º**\n",
    "    - åº”ç”¨å›¾åƒå¹³ç§»ã€ç¿»è½¬ç­‰æŠ€æœ¯æ‰©å……è®­ç»ƒæ•°æ®é›†\n",
    "    - æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "7. **ä½¿ç”¨å¤§è§„æ¨¡æ•°æ®é›† (ImageNet)**\n",
    "    - åœ¨ ImageNet ä¸Šè®­ç»ƒï¼ŒåŒ…å«ç™¾ä¸‡çº§å›¾ç‰‡å’Œåƒçº§ç±»åˆ«\n",
    "    - å¤§è§„æ¨¡æ•°æ®ä¸ºæ·±åº¦ç½‘ç»œæä¾›æ›´å¼ºçš„å­¦ä¹ èƒ½åŠ›\n",
    "\n",
    "## æ­¥éª¤ï¼š\n",
    "1. **æ•°æ®é¢„å¤„ç†ä¸åŠ è½½**\n",
    "    - æ•°æ®å¢å¼ºï¼ˆå¦‚éšæœºè£å‰ªã€æ°´å¹³ç¿»è½¬ï¼‰ä»¥æå‡æ³›åŒ–èƒ½åŠ›\n",
    "    - å½’ä¸€åŒ– å›¾åƒæ•°æ®ä»¥åŠ å¿«è®­ç»ƒæ”¶æ•›é€Ÿåº¦\n",
    "\n",
    "2. **å®šä¹‰ AlexNet æ¨¡å‹**\n",
    "    - æ­å»º8å±‚ç½‘ç»œç»“æ„ï¼ˆ5ä¸ªå·ç§¯å±‚ + 3ä¸ªå…¨è¿æ¥å±‚ï¼‰\n",
    "    - æ·»åŠ  ReLU æ¿€æ´»å‡½æ•°ã€LRN å±‚ã€Dropout å’Œ MaxPooling å±‚\n",
    "\n",
    "3. **å®šä¹‰æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨**\n",
    "    - ä½¿ç”¨ äº¤å‰ç†µæŸå¤±å‡½æ•° (CrossEntropyLoss)\n",
    "    - ä¼˜åŒ–å™¨é€‰æ‹© SGD+åŠ¨é‡\n",
    "\n",
    "4. **æ¨¡å‹è¯„ä¼°**\n",
    "    - ä½¿ç”¨æµ‹è¯•æ•°æ®é›†è¯„ä¼°å‡†ç¡®ç‡\n",
    "    - ç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿ä»¥æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. å¿…è¦åº“çš„å¯¼å…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe447e",
   "metadata": {},
   "source": [
    "### ğŸ“¦ **å¯¼å…¥å¿…è¦çš„åº“**\n",
    "åœ¨æœ¬éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯¼å…¥ç”¨äºæ•°æ®åŠ è½½ã€æ¨¡å‹æ„å»ºå’Œè®­ç»ƒçš„å¿…è¦åº“ã€‚\n",
    "- `torch` å’Œ `torchvision` ç”¨äºæ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚\n",
    "- `PIL` ç”¨äºå›¾åƒå¤„ç†ã€‚\n",
    "- `tqdm` ç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿›åº¦æ¡ï¼Œå¸®åŠ©è§‚å¯Ÿè®­ç»ƒè¿›åº¦ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# è·å–å½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'),'..'))\n",
    "# å¦‚æœçˆ¶ç›®å½•ä¸åœ¨ sys.pathä¸­ï¼Œåˆ™æ·»åŠ \n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "import utils\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available()\n",
    "                      else 'mps' if torch.mps.is_available()\n",
    "                      else 'cpu')\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. å¯¼å…¥æ•°æ®åº“å¹¶è½¬æ¢ä¸ºDataLoaderæ ¼å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fcbe2",
   "metadata": {},
   "source": [
    "### ğŸ–¼ï¸ **æ•°æ®é¢„å¤„ç†ä¸å¢å¼º**\n",
    "åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `torchvision.transforms` æ¥å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼š\n",
    "- `Resize` å’Œ `CenterCrop`ï¼šè°ƒæ•´å›¾åƒå¤§å°ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥ã€‚\n",
    "- `ToTensor`ï¼šå°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚\n",
    "- `Normalize`ï¼šå¯¹åƒç´ å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œæœ‰åŠ©äºæ¨¡å‹æ›´å¿«æ”¶æ•›ã€‚\n",
    "\n",
    "âš ï¸ **åˆå­¦è€…æç¤º**ï¼š\n",
    "- ç¡®ä¿ `mean` å’Œ `std` å€¼ä¸é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨çš„å€¼ä¸€è‡´ã€‚\n",
    "- è¾“å…¥å›¾åƒçš„å¤§å°åº”ä¸æ¨¡å‹æœŸæœ›çš„è¾“å…¥å¤§å°åŒ¹é…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {'train':transforms.Compose([\n",
    "                     transforms.RandomResizedCrop(224),             # éšæœºè£å‰ªå¹¶ç¼©æ”¾åˆ°224x224\n",
    "                     transforms.RandomHorizontalFlip(),             # éšæœºæ°´å¹³ç¿»è½¬\n",
    "                     transforms.ToTensor(),                         # è½¬ä¸ºTensor\n",
    "                     transforms.Normalize(mean=[0.485, 0.456, 0.406],# æŒ‰ImageNetå‡å€¼å’Œæ ‡å‡†å·®å½’ä¸€åŒ–\n",
    "                                          std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "             'val':transforms.Compose([\n",
    "                   transforms.Resize(256),                        # çŸ­è¾¹ç¼©æ”¾åˆ°256\n",
    "                   transforms.CenterCrop(224),                    # ä»ä¸­å¿ƒè£å‰ª224x224\n",
    "                   transforms.ToTensor(),                         # è½¬ä¸ºTensor\n",
    "                   transforms.Normalize(mean=[0.485, 0.456, 0.406],# æŒ‰ImageNetå‡å€¼å’Œæ ‡å‡†å·®å½’ä¸€åŒ–\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "             ]),\n",
    "             'test':transforms.Compose([\n",
    "                    transforms.Resize(256),                        # çŸ­è¾¹ç¼©æ”¾åˆ°256\n",
    "                    transforms.CenterCrop(224),                    # ä»ä¸­å¿ƒè£å‰ª224x224\n",
    "                    transforms.ToTensor(),                         # è½¬ä¸ºTensor\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406],# æŒ‰ImageNetå‡å€¼å’Œæ ‡å‡†å·®å½’ä¸€åŒ–\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n03444034\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–éªŒè¯é›†çš„æ ‡ç­¾\n",
    "val_labels = {}\n",
    "with open('../Datasets/tiny-imagenet-200/val/val_annotations.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        filename, label = parts[0], parts[1]\n",
    "        val_labels[filename] = label\n",
    "print(val_labels['val_0.JPEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageNet_train = datasets.ImageFolder(root='../Datasets/tiny-imagenet-200/train',transform=transform['train'])\n",
    "ImageNet_val = datasets.ImageFolder(root='../Datasets/tiny-imagenet-200/val',transform=transform['val'])\n",
    "ImageNet_test = datasets.ImageFolder(root='../Datasets/tiny-imagenet-200/test',transform=transform['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f223c",
   "metadata": {},
   "source": [
    "### ğŸš€ **æ•°æ®åŠ è½½å™¨ (DataLoader) è®¾ç½®**\n",
    "è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ `DataLoader` æ¥æ‰¹é‡åŠ è½½æ•°æ®ã€‚\n",
    "- `batch_size`ï¼šæ¯æ¬¡è¾“å…¥æ¨¡å‹çš„æ ·æœ¬æ•°é‡ã€‚\n",
    "- `shuffle`ï¼šåœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶æ‰“ä¹±æ•°æ®ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚\n",
    "- `num_workers`ï¼šè®¾ç½®åŠ è½½æ•°æ®çš„å­è¿›ç¨‹æ•°é‡ï¼Œæ•°å€¼å–å†³äºæœºå™¨çš„ CPU æ ¸æ•°ã€‚\n",
    "\n",
    "âš¡ **åˆå­¦è€…æ˜“é”™ç‚¹**ï¼š\n",
    "- å¦‚æœåœ¨ Windows æˆ– Jupyter Notebook ä¸­é‡åˆ°å¤šè¿›ç¨‹åŠ è½½é—®é¢˜ï¼Œè¯·å°è¯•å°† `num_workers=0`ã€‚\n",
    "- å¦‚æœæ•°æ®åŠ è½½æ¯”é¢„æœŸæ…¢ï¼Œå°è¯•è°ƒæ•´ `num_workers` æˆ–ä½¿ç”¨ `pin_memory=True`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 4\n",
    "ImageNet_train_iter = DataLoader(ImageNet_train,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "ImageNet_val_iter = DataLoader(ImageNet_val,batch_size=batch_size,shuffle=False,num_workers=num_workers)\n",
    "ImageNet_test_iter = DataLoader(ImageNet_test,batch_size=batch_size,shuffle=False,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n",
      "tensor([196,  50, 105, 100, 168,  58, 174, 140,  45, 131,  25, 128,   6,  98,\n",
      "         33, 117, 139, 194,  98,  89, 139,  41, 152,  25, 107,   7,  76,  18,\n",
      "          8,  73,  49, 148,  10,  33, 142, 142, 191,  47,  65,  41, 138,  80,\n",
      "        131,  93, 190,  18,  50,  90, 175,  34,  98, 108, 114, 197, 172,  78,\n",
      "          7, 101, 108, 137,  42,  93, 181, 168])\n"
     ]
    }
   ],
   "source": [
    "img_train = next(iter(ImageNet_train_iter))\n",
    "print(len(img_train))\n",
    "print(img_train[0].shape)\n",
    "print(img_train[1].shape)\n",
    "print(img_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "img_val = next(iter(ImageNet_val_iter))\n",
    "print(len(img_val))\n",
    "print(img_val[0].shape)\n",
    "print(img_val[1].shape)\n",
    "print(img_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä¼šå‘ç°è¿™é‡Œçš„æ ‡ç­¾éƒ¨åˆ†å¾ˆå¥‡æ€ªï¼Œå…¨éƒ½æ˜¯0ï¼Œè¿™æ˜¯å› ä¸ºvalæ•°æ®é›†å¹¶æ²¡æœ‰æŒ‰ç…§ImageFolderè¦æ±‚çš„æ ¼å¼è¿›è¡Œæ•´ç†ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è‡ªå·±å®šä¹‰æ•°æ®é›†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. è‡ªå®šä¹‰éªŒè¯é›†æ•°æ®é›†\n",
    "class TinyImageNetValDataset(Dataset):\n",
    "    def __init__(self, img_dir, val_labels, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_dict = val_labels\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(list(set(self.img_dict.values())))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.img_list = list(self.img_dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.class_to_idx[self.img_dict[img_name]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047a46b",
   "metadata": {},
   "source": [
    "### ğŸš€ **æ•°æ®åŠ è½½å™¨ (DataLoader) è®¾ç½®**\n",
    "è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ `DataLoader` æ¥æ‰¹é‡åŠ è½½æ•°æ®ã€‚\n",
    "- `batch_size`ï¼šæ¯æ¬¡è¾“å…¥æ¨¡å‹çš„æ ·æœ¬æ•°é‡ã€‚\n",
    "- `shuffle`ï¼šåœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶æ‰“ä¹±æ•°æ®ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚\n",
    "- `num_workers`ï¼šè®¾ç½®åŠ è½½æ•°æ®çš„å­è¿›ç¨‹æ•°é‡ï¼Œæ•°å€¼å–å†³äºæœºå™¨çš„ CPU æ ¸æ•°ã€‚\n",
    "\n",
    "âš¡ **åˆå­¦è€…æ˜“é”™ç‚¹**ï¼š\n",
    "- å¦‚æœåœ¨ Windows æˆ– Jupyter Notebook ä¸­é‡åˆ°å¤šè¿›ç¨‹åŠ è½½é—®é¢˜ï¼Œè¯·å°è¯•å°† `num_workers=0`ã€‚\n",
    "- å¦‚æœæ•°æ®åŠ è½½æ¯”é¢„æœŸæ…¢ï¼Œå°è¯•è°ƒæ•´ `num_workers` æˆ–ä½¿ç”¨ `pin_memory=True`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageNet_val = TinyImageNetValDataset(\n",
    "    img_dir='../Datasets/tiny-imagenet-200/val/images',\n",
    "    val_labels=val_labels,\n",
    "    transform=transform['val'])\n",
    "ImageNet_val_iter = DataLoader(ImageNet_val, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä¼šå‘ç°æ­¤å¤„num_workersè®¾ç½®ä¸º0ï¼Œè¿™æ˜¯å› ä¸ºåœ¨num_workerså¤§äº0æ—¶ï¼Œä¼šå‡ºç°å¦‚ä¸‹é”™è¯¯ï¼š\n",
    "```bash\n",
    "AttributeError: Can't get attribute 'TinyImageNetValDataset' on <module '__main__' (built-in)>\n",
    "```\n",
    "#### ğŸ” é—®é¢˜æ ¹æº\n",
    "PyTorch åœ¨ä½¿ç”¨ DataLoader æ—¶ï¼Œå¦‚æœ num_workers > 0ï¼Œä¼šä½¿ç”¨å¤šè¿›ç¨‹æ¥åŠ é€Ÿæ•°æ®åŠ è½½ã€‚åœ¨ Windows æˆ–éƒ¨åˆ† IDE ç¯å¢ƒï¼ˆå¦‚ Jupyter Notebookï¼‰ä¸­ï¼Œå¤šè¿›ç¨‹ä¼šå°è¯•é‡æ–°å¯¼å…¥ä¸»æ¨¡å—ï¼ˆ`__main__`ï¼‰ï¼Œå¦‚æœè‡ªå®šä¹‰çš„ Dataset ç±»æ²¡æœ‰åœ¨æ¨¡å—çš„é¡¶å±‚ï¼ˆå³å…¨å±€ä½œç”¨åŸŸä¸­å®šä¹‰ï¼‰ï¼Œå°±ä¼šå¯¼è‡´ä»¥ä¸ŠæŠ¥é”™ã€‚\n",
    "\n",
    "#### âš¡ è§£å†³æ–¹æ³•\n",
    "\n",
    "**âœ… æ–¹æ³•ä¸€ï¼šå°† num_workers è®¾ç½®ä¸º 0**\n",
    "\n",
    "è¿™æ˜¯æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºè°ƒè¯•å’Œå°è§„æ¨¡æ•°æ®é›†ï¼š\n",
    "```python\n",
    "val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=0)\n",
    "```\n",
    "\n",
    "**âœ… æ–¹æ³•äºŒï¼šä½¿ç”¨ if __name__ == \"__main__\": åŒ…è£¹ä¸»ä»£ç **\n",
    "\n",
    "è¿™æ˜¯æœ€æ¨èçš„æ–¹æ³•ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®é›†ï¼š\n",
    "\n",
    "å¦‚æœä½ åœ¨ .py æ–‡ä»¶ä¸­è¿è¡Œä»£ç ï¼Œåº”ä½¿ç”¨å¦‚ä¸‹ç»“æ„æ¥é¿å…å¤šè¿›ç¨‹å¯¼å…¥é—®é¢˜ï¼š\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "    img_val = next(iter(val_loader))\n",
    "    print(len(img_val))\n",
    "    print(img_val[0].shape)\n",
    "    print(img_val[1].shape)\n",
    "    print(img_val[1])\n",
    "```\n",
    "\n",
    "**âœ… æ–¹æ³•ä¸‰ï¼šç¡®ä¿ TinyImageNetValDataset å®šä¹‰åœ¨æ¨¡å—é¡¶å±‚**\n",
    "\n",
    "å¦‚æœä½ æ˜¯é€šè¿‡ import å¯¼å…¥æ•°æ®é›†å®šä¹‰çš„ï¼Œè¯·ç¡®è®¤ TinyImageNetValDataset å®šä¹‰åœ¨æ–‡ä»¶çš„æœ€å¤–å±‚ï¼Œè€Œä¸æ˜¯åœ¨å‡½æ•°æˆ–ç±»å†…éƒ¨ã€‚\n",
    "\n",
    "#### ğŸ’¡ ä¸ºä»€ä¹ˆ if __name__ == \"__main__\": èƒ½è§£å†³é—®é¢˜ï¼Ÿ\n",
    "\n",
    "åœ¨ Windows å’Œéƒ¨åˆ† IDE ä¸­ï¼ŒPyTorch ä¸ºäº†å®ç°å¤šè¿›ç¨‹ï¼Œä¼šåœ¨å­è¿›ç¨‹ä¸­é‡æ–°æ‰§è¡Œä¸»è„šæœ¬ã€‚å¦‚æœä¸ä½¿ç”¨ if __name__ == \"__main__\": æ¥ä¿æŠ¤ä¸»ä»£ç ï¼Œå­è¿›ç¨‹å°±ä¼šé‡å¤æ‰§è¡Œæ•°æ®åŠ è½½æˆ–æ¨¡å‹è®­ç»ƒä»£ç ï¼Œå¯¼è‡´æ‰¾ä¸åˆ° TinyImageNetValDataset ç±»çš„å®šä¹‰ã€‚\n",
    "\n",
    "#### ğŸ¯ æ€»ç»“\n",
    "è°ƒè¯•ç”¨ï¼šå°† num_workers=0ã€‚\n",
    "\n",
    "æ­£å¼è®­ç»ƒç”¨ï¼šä½¿ç”¨ if `__name__ == \"__main__\"`: æ¥åŒ…è£¹ä¸»ä»£ç ã€‚\n",
    "\n",
    "è·¨æ–‡ä»¶å¼•ç”¨ï¼šå°† TinyImageNetValDataset ç±»æ”¾åœ¨æ¨¡å—é¡¶å±‚æˆ–å•ç‹¬çš„ .py æ–‡ä»¶ä¸­è¿›è¡Œå¯¼å…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n",
      "tensor([107, 139, 140,  69,  69, 161, 147,  73, 145,  39, 158, 188,  39, 120,\n",
      "         21,  79,  33, 165, 153, 119, 123, 124,  18,   1, 170, 141, 171, 158,\n",
      "         79,  25, 121, 179, 124, 130, 176,  86,   6, 129, 142, 127,  33,  33,\n",
      "         44,  40, 110,  40, 159, 184,  57,  80,   9,  34,  39,  14,  75, 199,\n",
      "         10,  99,  66, 160,  69, 177,  25, 101])\n"
     ]
    }
   ],
   "source": [
    "img_val = next(iter(ImageNet_val_iter))\n",
    "print(len(img_val))\n",
    "print(img_val[0].shape)\n",
    "print(img_val[1].shape)\n",
    "print(img_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœä½ æ¯”è¾ƒç»†å¿ƒçš„è¯ï¼Œä½ ä¼šå‘ç°ä¸€ä¸ªå¾ˆå¥‡æ€ªçš„é—®é¢˜ï¼šä¸ºä»€ä¹ˆnum_workers=4çš„æ—¶å€™åŠ è½½æ—¶é—´åè€Œæ¯”num_workers=0çš„æ—¶å€™è¦é•¿ï¼Ÿ\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªåœ¨ä½¿ç”¨ PyTorch DataLoader æ—¶å¸¸è§çš„é—®é¢˜ã€‚è™½ç„¶ç†è®ºä¸Šå¢åŠ  num_workers åº”è¯¥æå‡æ•°æ®åŠ è½½é€Ÿåº¦ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œnum_workers=4 æ¯” num_workers=0 æ›´æ…¢ï¼ŒåŸå› å¯èƒ½æ¶‰åŠä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n",
    "\n",
    "#### 1. ç¡¬ä»¶ç“¶é¢ˆ\n",
    "\n",
    "**CPU æ ¸å¿ƒæ•°é‡ä¸è¶³**ï¼š\n",
    "\n",
    "å¦‚æœä½ çš„æœºå™¨ CPU æ ¸å¿ƒè¾ƒå°‘ï¼ˆå¦‚ 4 æ ¸æˆ–æ›´å°‘ï¼‰ï¼Œnum_workers=4 ä¼šä¸ä¸»è¿›ç¨‹ç«äº‰ CPU èµ„æºï¼Œåè€Œå¯¼è‡´æ•´ä½“é€Ÿåº¦å˜æ…¢ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**ï¼šå°† num_workers è®¾ç½®ä¸º CPUæ ¸å¿ƒæ•° - 1ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "num_workers = multiprocessing.cpu_count() - 1\n",
    "```\n",
    "\n",
    "**ç£ç›˜ I/O ç“¶é¢ˆ**ï¼š\n",
    "\n",
    "æ•°æ®åŠ è½½ç“¶é¢ˆå¯èƒ½åœ¨ç£ç›˜è¯»å†™é€Ÿåº¦ï¼ˆç‰¹åˆ«æ˜¯æœºæ¢°ç¡¬ç›˜ HDDï¼‰ã€‚å¤šè¿›ç¨‹åŒæ—¶è¯»å–æ—¶ï¼Œä¼šå¢åŠ ç£ç›˜éšæœºè¯»å–å‹åŠ›ï¼Œå¯¼è‡´åè€Œæ›´æ…¢ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ SSD æˆ–å°†æ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­ã€‚\n",
    "\n",
    "#### 2. æ•°æ®é¢„å¤„ç†å¼€é”€\n",
    "\n",
    "å¦‚æœ transform æ“ä½œè¾ƒä¸ºå¤æ‚ï¼ˆå¦‚å¤§é‡çš„å®æ—¶æ•°æ®å¢å¼ºï¼‰ï¼Œæ¯ä¸ª worker çš„å¼€é”€ä¼šå˜å¤§ã€‚å¤šè¿›ç¨‹å¹¶å‘æ‰§è¡Œè¿™äº› CPU å¯†é›†å‹ä»»åŠ¡ä¼šå¯¼è‡´èµ„æºäº‰ç”¨ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**ï¼šç®€åŒ– transform æ“ä½œï¼Œæˆ–ä½¿ç”¨å¼‚æ­¥é¢„å¤„ç†ã€‚é¢„å…ˆå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†å¹¶ä¿å­˜ä¸ºæ›´é«˜æ•ˆçš„æ ¼å¼ï¼ˆå¦‚ .ptã€HDF5 æˆ– LMDBï¼‰ã€‚\n",
    "\n",
    "#### 3. å†…å­˜é™åˆ¶ä¸æ•°æ®å¤åˆ¶\n",
    "\n",
    "å¤šè¿›ç¨‹ä¼šå¯¼è‡´æ•°æ®åœ¨ä¸åŒè¿›ç¨‹ä¹‹é—´è¿›è¡Œå¤åˆ¶ï¼Œå†…å­˜å¼€é”€å¢åŠ ã€‚å°¤å…¶åœ¨å†…å­˜è¾ƒå°çš„è®¾å¤‡ä¸Šï¼Œé¢‘ç¹çš„æ•°æ®å¤åˆ¶ä¼šæ‹–æ…¢é€Ÿåº¦ã€‚\n",
    "\n",
    "PyTorch 1.7+ æä¾›äº† persistent_workers=True å‚æ•°ï¼Œå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼š\n",
    "```python\n",
    "DataLoader(dataset, batch_size=64, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "```\n",
    "pin_memory=True ä¼šå°†æ•°æ®é¢„åŠ è½½åˆ° GPU å›ºå®šå†…å­˜ï¼Œå‡å°‘ CPU å’Œ GPU ä¹‹é—´çš„æ•°æ®ä¼ è¾“å¼€é”€ã€‚\n",
    "\n",
    "#### 4. Python GILï¼ˆå…¨å±€è§£é‡Šå™¨é”ï¼‰\n",
    "\n",
    "è™½ç„¶ PyTorch çš„ DataLoader ä½¿ç”¨ multiprocessing æ¨¡å—æ¥ç»•è¿‡ GILï¼Œä½†å¦‚æœä½ åœ¨ Dataset ä¸­ä½¿ç”¨äº† Python åŸç”Ÿçš„ I/O å¯†é›†å‹ä»£ç ï¼ˆå¦‚å­—ç¬¦ä¸²è§£æã€CSV è¯»å–ç­‰ï¼‰ï¼Œå¯èƒ½ä¼šå—é™äº GILï¼Œä»è€Œæ— æ³•å……åˆ†åˆ©ç”¨å¤šæ ¸ CPUã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ numpyã€pandas æˆ– PyTorch åŸç”Ÿçš„æ•°æ®å¤„ç†æ–¹æ³•ï¼Œå‡å°‘ Python å±‚çº§çš„å¾ªç¯å’Œ I/Oã€‚\n",
    "\n",
    "#### 5. å¾ˆå‰å®³çš„è§£å†³æ–¹æ³•ï¼šæ‰¾åˆ°æœ€ä½³ num_workersè®¾ç½®\n",
    "\n",
    "**æµ‹è¯• num_workers**ï¼š\n",
    "```python\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def find_best_num_workers(dataset, batch_size=128):\n",
    "    for num_workers in range(0, 9):\n",
    "        start = time.time()\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "        for _ in loader:\n",
    "            pass\n",
    "        end = time.time()\n",
    "        print(f\"num_workers={num_workers} --> {end - start:.2f} ç§’\")\n",
    "\n",
    "# è°ƒç”¨å‡½æ•°\n",
    "find_best_num_workers(train_data)\n",
    "```\n",
    "é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ å¯ä»¥æµ‹è¯•å¹¶æ‰¾åˆ°å½“å‰ç¡¬ä»¶å’Œæ•°æ®é…ç½®ä¸‹çš„æœ€ä¼˜ num_workersã€‚\n",
    "\n",
    "#### æ€»ç»“ï¼šä¸ºä»€ä¹ˆ num_workers=4 ä¼šæ¯” num_workers=0 æ…¢ï¼Ÿ\n",
    "| åŸå›                | è§£é‡Š                                             | è§£å†³æ–¹æ³•                                                   |\n",
    "|--------------------|--------------------------------------------------|----------------------------------------------------------|\n",
    "| ç¡¬ä»¶ç“¶é¢ˆ           | CPU æ ¸å¿ƒæ•°é‡ä¸è¶³æˆ–ç£ç›˜ I/O ç“¶é¢ˆ                   | è®¾ç½®åˆé€‚çš„ num_workers æˆ–ä¼˜åŒ–ç¡¬ä»¶é…ç½®                      |\n",
    "| æ•°æ®é¢„å¤„ç†å¼€é”€     | å¤æ‚çš„ transform æ“ä½œå¯¼è‡´æ¯ä¸ª worker å¼€é”€å˜å¤§     | ç®€åŒ– transform æ“ä½œæˆ–ä½¿ç”¨å¼‚æ­¥é¢„å¤„ç†                        |\n",
    "| CPU æ ¸å¿ƒæ•°ä¸è¶³     | å¤šè¿›ç¨‹ä¸ä¸»è¿›ç¨‹äº‰ç”¨èµ„æºï¼Œå¯¼è‡´é€Ÿåº¦å˜æ…¢              | è®¾ç½®ä¸º CPU æ ¸å¿ƒæ•°-1 æˆ–æ ¹æ®æµ‹è¯•ç»“æœåŠ¨æ€è°ƒæ•´                 |\n",
    "| ç£ç›˜ I/O ç“¶é¢ˆ      | å¤šè¿›ç¨‹åŒæ—¶è¯»å–æ•°æ®ï¼Œå¯¼è‡´ç£ç›˜éšæœºè¯»å†™å‹åŠ›å˜å¤§      | ä½¿ç”¨ SSD æˆ–å°†æ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­                             |\n",
    "| å†…å­˜é™åˆ¶ä¸æ•°æ®å¤åˆ¶ | å¤šè¿›ç¨‹å¯¼è‡´æ•°æ®åœ¨ä¸åŒè¿›ç¨‹ä¹‹é—´å¤åˆ¶ï¼Œå†…å­˜å¼€é”€å¢åŠ     | ä½¿ç”¨ pin_memory=True å’Œ persistent_workers=True          |\n",
    "\n",
    "#### æœ€ç»ˆå»ºè®®\n",
    "- å°æ•°æ®é›†ï¼šnum_workers=0 åè€Œæ›´å¿«ï¼Œå› ä¸ºæ•°æ®åŠ è½½å¼€é”€è¾ƒå°ã€‚\n",
    "- å¤§æ•°æ®é›† + SSD + å¤šæ ¸ CPUï¼šæµ‹è¯• num_workersï¼Œä¸€èˆ¬ä¸º [2, 4, 8] ä¸­çš„å€¼ã€‚\n",
    "- å†…å­˜å……è¶³ + GPUï¼špin_memory=True å¯ä»¥æ˜¾è‘—æå‡æ•°æ®ä» CPU åˆ° GPU çš„åŠ è½½é€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. å»ºç«‹ç¼–å·åˆ°ç§ç±»çš„æ˜ å°„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfish, Carassius auratus\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–ç±»åˆ« IDï¼ˆwnids.txtï¼‰\n",
    "with open('tiny-imagenet-200/wnids.txt') as f:\n",
    "    wnids = [line.strip() for line in f]\n",
    "\n",
    "# è¯»å–ç±»åˆ«åç§°å’Œæè¿°ï¼ˆwords.txtï¼‰\n",
    "class_names = {}\n",
    "with open('tiny-imagenet-200/words.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        class_names[parts[0]] = parts[1]\n",
    "print(class_names['n01443537'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. å®šä¹‰AlexNetç½‘ç»œ\n",
    "\n",
    "**æ€»ç»“**ï¼šä¸ºä»€ä¹ˆç›¸æ¯”äºLeNetè¦æ·»åŠ æœ€åä¸‰ä¸ªä¸æ”¹å˜å›¾åƒåƒç´ çš„å·ç§¯å±‚\n",
    "1. å­¦ä¹ èƒ½åŠ›å¢å¼ºï¼šå¢åŠ ç½‘ç»œçš„æ·±åº¦å’Œå­¦ä¹ å¤æ‚ç‰¹å¾çš„èƒ½åŠ›ã€‚\n",
    "2. é¿å…ä¿¡æ¯ä¸¢å¤±ï¼šä¿ç•™å›¾åƒçš„ç©ºé—´ç»†èŠ‚ï¼Œä¸å‡å°‘å›¾åƒåˆ†è¾¨ç‡ã€‚\n",
    "3. è®¡ç®—æ•ˆç‡ï¼šå‡å°‘å‚æ•°å’Œè®¡ç®—é‡ï¼Œé¿å…è¿‡åº¦å‹ç¼©å›¾åƒã€‚\n",
    "4. å…¨å±€ç‰¹å¾æå–ï¼šé€æ­¥ä»å±€éƒ¨ç‰¹å¾æå–åˆ°æ›´å…¨å±€çš„ç‰¹å¾ï¼Œå¢å¼ºåˆ†ç±»èƒ½åŠ›ã€‚\n",
    "è¿™ç§è®¾è®¡æ˜¯é€šè¿‡ `ä¸ç¼©å°å›¾åƒå°ºå¯¸` ä½† `å¢åŠ ç‰¹å¾æ•°é‡` æ¥åŠ å¼ºæ¨¡å‹çš„è¡¨ç°åŠ›ï¼Œè¿™å¯¹äºæ·±åº¦ç¥ç»ç½‘ç»œçš„æˆåŠŸè®­ç»ƒèµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),# ç»“æŸååƒç´ ä¸º55\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), # ç»“æŸååƒç´ ä¸º27\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # ç»“æŸååƒç´ ä¸º27\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), # ç»“æŸååƒç´ ä¸º13\n",
    "            # è¿ç»­ä¸‰ä¸ª3*3çš„å·ç§¯å±‚ï¼Œæ”¹å˜äº†é€šé“æ•°ï¼Œ\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # åƒç´ ä¸º13\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # åƒç´ ä¸º13\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # åƒç´ ä¸º13\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)) # åƒç´ ä¸º6\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 200))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Linear(in_features=4096, out_features=200, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.training_loop(model=net,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    train_iter=ImageNet_train_iter,\n",
    "                    test_iter=ImageNet_val_iter,\n",
    "                    epochs=15,\n",
    "                    device=device,\n",
    "                    print_every=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
